# Scrapy实习爬虫-获取水木清华上面的实习信息


### 介绍 ###

学习爬虫的时候就在思考爬虫爬下来的数据有什么用。正好最近想找实习，萌生了写一个实习爬虫的想法。
实现以下功能：

- 爬取水木清华、北邮人等靠谱实习站点上的实习兼职板块上的信息。
- 数据进行一些处理后，存储到mongodb数据库中

待做的功能：

- 公众号中实现查找功能。比如，输入“算法工程师”，公众号中推送近20条算法工程师的实习信息。
- 对实习要求信息进行处理。比如，对于“算法工程师”职位，对几千条相关信息检索后找出高频关键词，做成词云。
- 不同实习岗位的工资分析。

### 基于 ###

- python 3.5
- Scrapy 1.3
- mongodb
- pymongo

### 运行  ###
clone代码到本地

`git clone git@github.com:ethanww/shixispider.git`

进入环境

`cd shixispider`

运行scrapy(要确定你的mongodb打开)

`scrapy crawl shixi`

### 代码运行提示

cookie需要有效。